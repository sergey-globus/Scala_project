# SessionMapReduceApp

## Используемые версии зависимостей и плагинов

- Scala version: **2.12.18**  
- Spark version: **3.5.0**  
- Java compiler source/target: **11**

## Сборка и запуск

Для сборки проекта (JAR-файла с контейнером всех зависимостей) используется Maven:
```
mvn clean compile
```

После этого JAR-файл будет находиться в директории `target`, обычно с именем вида `spark-project-1.0-SNAPSHOT-jar-with-dependencies.jar`.

Для запуска приложения используйте команду `spark-submit`:

```
spark-submit --class org.example.SessionMapReduceApp --master local[*] target/spark-project-1.0-SNAPSHOT-jar-with-dependencies.jar [input_path] [output_path]
```

Где:
- `input_path` — путь к входным данным (по умолчанию `data/Сессии/*`)
- `output_path` — путь, куда будут сохранены результаты (по умолчанию `result`)

## Объяснение строки с `unknown` в выводе файла

В выходных данных для каждого открытия документа фиксируется дата в формате `dd.MM.yyyy`, извлекаемая из метки времени (timestamp). Однако в некоторых случаях дата становится `"unknown"`. Это происходит если:

- Метка времени отсутствует или она пустая.
- Не удалось распарсить английскую дату из-за ошибок в формате.
- Используются редкие или нераспознанные форматы timestamp, которые не входят в список известных шаблонов.

В таких ситуациях для записи используется дата `"unknown"`. Если в конфигурации проекта установлено `dropUnknownDates = true`, то записи с `"unknown"` не сохраняются, предотвращая попадание некорректных данных в итоговый файл. Если же опция выключена (по умолчанию), данные с `"unknown"` остаются, чтобы не терять событие вовсе.

